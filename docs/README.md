<div align="center">

# `polaris~`

<img src="demo.gif" width="680"/>

**An Audiovisual Augmented Reality Experience Built on Open-Source Hardware and Software**



[![Platform](https://img.shields.io/badge/Platform-Windows-yellow?style=flat-square&logo=windows)](https://www.microsoft.com/en-gb/windows/)
[![Environment](https://img.shields.io/badge/Environment-Unity/Pd-orange?style=flat-square&logo=unity&logoColor=white)](https://unity.com/)
[![Publication](https://img.shields.io/badge/Publication-NIME-green?style=flat-square&logo=readthedocs&logoColor=white)](https://doi.org/10.21428/92fbeb44.8abb9ce6)
[![Documentation](https://img.shields.io/badge/Guide-Wiki-red?style=flat-square&logo=todoist&logoColor=white)](https://github.com/sambilbow/polaris/wiki)
[![Project](https://img.shields.io/badge/Project-Blog-blue?style=flat-square&logo=jekyll&logoColor=white)](https://sambilbow.com/projects/polaris/)
[![Discord](https://img.shields.io/badge/Discord-XRt%20Space-%237289da.svg?style=flat-square&logo=discord&logoColor=white)](https://discord.gg/p3MmURSBV3)


</div>

If an AR system can be thought of as one that combines real and virtual processes, is interactive in real-time, and is registered in three dimensions; why do we witness the majority of AR applications utilising primarily visual displays of information? I propose a practice-led compositional approach for developing multisensory AR experiencesâ€™, arguing that, as an medium that combines real and virtual multisensory processes, it must explored with a multisensory approach.

This project uses the open-source [Project North Star](https://docs.projectnorthstar.org/) HMD from Leap Motion alongside bone-conduction headphones to deliver a spatialised audio-visual experience via Unity called polaris~. This repository started off as a fork of the [Software Companion](https://github.com/HyperLethalVector/ProjectEsky-UnityIntegration) for Project North Star, hence the other repository contributors and long list of commits. However, the experience itself including all audio-visual / artistic / musical content was added afterwards.



<div align="center">
<br>

[![{Presentation}](https://ytcards.demolab.com/?id=eCdQku5hFOE&title=Presentation&lang=en&timestamp=1655660340&background_color=%230d1117&title_color=%23ffffff&stats_color=%23dedede&width=250&duration=548 "Presentation")](https://youtu.be/eCdQku5hFOE)
[![{Demonstration}](https://ytcards.demolab.com/?id=lCBgMs8ULj0&title=Demonstration&lang=en&timestamp=1634924340&background_color=%230d1117&title_color=%23ffffff&stats_color=%23dedede&width=250&duration=529 "Demonstration")](https://youtu.be/lCBgMs8ULj0)
[![{Prototype}](https://ytcards.demolab.com/?id=gY2QtK907cU&title=Prototype&lang=en&timestamp=1632850740&background_color=%230d1117&title_color=%23ffffff&stats_color=%23dedede&width=250&duration=174 "Prototype")](https://youtu.be/gY2QtK907cU)
[![{Palm Synth}](https://ytcards.demolab.com/?id=miQI4jetETs&title=Palm+Synth&lang=en&timestamp=1629308340&background_color=%230d1117&title_color=%23ffffff&stats_color=%23dedede&width=250&duration=90 "Palm Synth")](https://youtu.be/miQI4jetETs)
[![{Finger Synth}](https://ytcards.demolab.com/?id=dJUd0186NbA&title=Finger+Synth&lang=en&timestamp=1629135540&background_color=%230d1117&title_color=%23ffffff&stats_color=%23dedede&width=250&duration=36 "Finger Synth")](https://youtu.be/dJUd0186NbA)
[![{LibPd Explainer}](https://ytcards.demolab.com/?id=CzJlEEcOt-A&title=LibPd+Explainer&lang=en&timestamp=1629049140&background_color=%230d1117&title_color=%23ffffff&stats_color=%23dedede&width=250&duration=799 "LibPd Explainer")](https://youtu.be/CzJlEEcOt-A)

</div>

<details>
<summary><h2>Inspiration and Similar Projects</h2></summary>
 
- [Listening Mirrors](http://listeningmirrors.net/): an audio AR interactive installation by my PhD supervisors
- [Laetitia Sonami](https://sonami.net/): pioneer in early glove-based interactive music systems
- [Atau Tanaka](https://www.youtube.com/watch?v=p8CKjmE7zys): interactive gestural synthesis using muscle sensors
- [Keijiro Takahashi](https://github.com/keijiro) specifically their work with audio-reactivity in Unity.
- [Tekh:2](https://github.com/TEKH2/XR-Audio-Visual-Instruments) has created XR instruments using granular synthesis in Unity.
- [Amy Brandon](https://www.amybrandon.ca/) creates amazing musical AR performances.
</details>

<details>
<summary><h2>Acknowledgements</h2></summary>

- [Noah Zerkin](https://twitter.com/noazark) (CombineReality) for their help in understanding some specifics workings of the North Star headset.
- [Damien Rompapas](https://www.linkedin.com/in/dr-damien-rompapas-3a4b63170/?originalSubdomain=jp) (BEERLabs / ThinkDigital) for their explaining and debugging of the Software Companion to me.
- [Bryan Chris Brown](https://twitter.com/BryanChrisBrown) (CombineReality) for their moderation of the very friendly [Discord server](https://discord.gg/WnzNZa3qnf) and considerable explanations of the benefits of working with the North Star headset.
</details>

<details>
<summary><h2>Credits</h2></summary>

- [Project North Star](https://docs.projectnorthstar.org/) is the 3D printable AR headset by LeapMotion that has been open-source since 2018.

- [Software Companion](https://github.com/HyperLethalVector/ProjectEsky-UnityIntegration) for Project North Star is developed by [Damien Rompapas](/) at BEERLabs / ThinkDigital. **If you use polaris~ in an academic context, please cite [their paper](https://dl.acm.org/doi/10.1145/3411763.3451804)**

- [LibPdIntegration](https://github.com/LibPdIntegration/LibPdIntegration) is developed by [Niall Moody](http://www.niallmoody.com) at [Abertay University](http://www.abertay.ac.uk), with assistance from [Yann Seznec](http://www.yannseznec.com/). It is licensed under the [MIT License](https://github.com/LibPdIntegration/LibPdIntegration/blob/master/LICENSE.txt).

- [Automatonism](https://www.automatonism.com/the-software) is developed by [Johan Erikkson](https://www.linkedin.com/in/johan-eriksson-ph-d-84393a56/).
</details>

## Citation
Bilbow, S. (2022). Evaluating polaris~ - An Audiovisual Augmented Reality Experience Built on Open-Source Hardware and Software. NIME 2022. https://doi.org/10.21428/92fbeb44.8abb9ce6


or [with BibTeX](citation.bib)
